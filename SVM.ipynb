{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \n",
    "    for column in ['x', 'y', 'z']:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df\n",
    "\n",
    "def segment(df, window_size, step_size):\n",
    "    segments = []\n",
    "    for start in range(0, len(df) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "\n",
    "        \\\n",
    "        segment = df.iloc[start:end]\n",
    "        segments.append(segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_activities(window_size=32, step_size=16):\n",
    "    # window_size = 160  # 2.5 seconds\n",
    "    # step_size = 20  # 75% overlap\n",
    "\n",
    "    activities_path = r'D:\\PersonalFiles\\MS_Analysis\\Activity'\n",
    "    activity_segments = {}\n",
    "\n",
    "    # Iterate over each activity's folder\n",
    "    for activity_name in os.listdir(activities_path):\n",
    "        print(activity_name)\n",
    "        activity_folder = os.path.join(activities_path, activity_name)\n",
    "        if os.path.isdir(activity_folder):\n",
    "            # Store segments for each activity\n",
    "            activity_segments[activity_name] = []\n",
    "            \n",
    "            # Iterate over each CSV file within the activity's folder\n",
    "            for filename in os.listdir(activity_folder):\n",
    "                if filename.endswith('.csv'):\n",
    "                    file_path = os.path.join(activity_folder, filename)\n",
    "                    \n",
    "                    # Read  CSV file\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    \n",
    "                    # Normalize data\n",
    "                    df_normalized = normalize(df)\n",
    "                    \n",
    "                    # Segment the data using a rolling window\n",
    "                    segments = segment(df_normalized, window_size, step_size)\n",
    "                    \n",
    "                    # Append the segments to the activity's list\n",
    "                    activity_segments[activity_name].extend(segments)\n",
    "    return activity_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_SKLearn(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            # Assuming segment is a pandas DataFrame and flattening it to a 1D array\n",
    "            feature_vector = segment.to_numpy().flatten()\n",
    "            X.append(feature_vector)\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"compiling model\")\n",
    "    # Define the SVM model\n",
    "    model = svm.SVC(kernel='rbf', gamma='scale', C=1.0)\n",
    "\n",
    "    print(\"training model\")\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = model.score(X_test_scaled, y_test)\n",
    "    print(f\"Model evaluation complete. Accuracy: {accuracy}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_TensorFlow(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            feature_vector = segment.to_numpy().flatten()\n",
    "            X.append(feature_vector)\n",
    "            y.append(activity_name)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Change labels to 1 and -1\n",
    "    y_train = np.where(y_train > 0, 1, -1)\n",
    "    y_test = np.where(y_test > 0, 1, -1)\n",
    "\n",
    "    # Define the SVM model by Tensorflow\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1, input_shape=(X_train_scaled.shape[1],))\n",
    "    ])\n",
    "\n",
    "    # Custom hinge loss\n",
    "    def hinge_loss(y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.maximum(1 - y_true * y_pred, 0))\n",
    "\n",
    "    model.compile(optimizer='sgd', loss=hinge_loss, metrics=['accuracy'])\n",
    "\n",
    "    print(\"compiled model\\nTraining Model\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test_scaled, y_test)\n",
    "    print(model.evaluate(X_test_scaled, y_test))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Second Window, 1 Second Overlap Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing SVM with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1_T1_ (WALK)\n",
      "B1_T2_ (WALK)\n",
      "B1_TWT_A_ (WALK)\n",
      "B1_TWT_B_ (WALK)\n",
      "B2_T1_ (WALK)\n",
      "B2_T2_ (WALK)\n",
      "B2_TWT_A_ (WALK)\n",
      "B2_TWT_B_ (WALK)\n",
      "digit symbol task_ (SIT)\n",
      "HR Recovery_ (STAND or SIT)\n",
      "Montreal Cognitive Assessment_ (SIT)\n",
      "Motor Behavioral\n",
      "Motor Behavioral task\n",
      "Motor behavioral task(1)\n",
      "Motor Behavioral Task_ (All conditions seen here)\n",
      "Naughton\n",
      "Naughton Task\n",
      "Naughton test\n",
      "Naughton Test_ (WALK)\n",
      "SOT_ (STAND)\n",
      "TM comfortable speed\n",
      "TM Comfortable speed(1)\n",
      "TM Comfortable Speed_ (WALK)\n",
      "TNT\n",
      "trail making task_ (SIT)\n",
      "Training ITWT - A\n",
      "Training ITWT - B\n",
      "Training ITWT -B\n",
      "Training_ TWT_A\n",
      "Training_ TWT_B\n",
      "Training_TWT_A\n",
      "Training_TWT_B\n",
      "TWT_A training\n",
      "TWT_A Training_ (WALK)\n",
      "TWT_B training\n",
      "TWT_B Training_ (WALK)\n",
      "segments in suitable format\n",
      "labels encoded\n",
      "compiling model\n",
      "training model\n"
     ]
    }
   ],
   "source": [
    "activity_segments = segment_activities(160, 36)\n",
    "model = fit_model_SKLearn(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing SVM with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1_T1_ (WALK)\n",
      "B1_T2_ (WALK)\n",
      "B1_TWT_A_ (WALK)\n",
      "B1_TWT_B_ (WALK)\n",
      "B2_T1_ (WALK)\n",
      "B2_T2_ (WALK)\n",
      "B2_TWT_A_ (WALK)\n",
      "B2_TWT_B_ (WALK)\n",
      "digit symbol task_ (SIT)\n",
      "HR Recovery_ (STAND or SIT)\n",
      "Montreal Cognitive Assessment_ (SIT)\n",
      "Motor Behavioral\n",
      "Motor Behavioral task\n",
      "Motor behavioral task(1)\n",
      "Motor Behavioral Task_ (All conditions seen here)\n",
      "Naughton\n",
      "Naughton Task\n",
      "Naughton test\n",
      "Naughton Test_ (WALK)\n",
      "SOT_ (STAND)\n",
      "TM comfortable speed\n",
      "TM Comfortable speed(1)\n",
      "TM Comfortable Speed_ (WALK)\n",
      "TNT\n",
      "trail making task_ (SIT)\n",
      "Training ITWT - A\n",
      "Training ITWT - B\n",
      "Training ITWT -B\n",
      "Training_ TWT_A\n",
      "Training_ TWT_B\n",
      "Training_TWT_A\n",
      "Training_TWT_B\n",
      "TWT_A training\n",
      "TWT_A Training_ (WALK)\n",
      "TWT_B training\n",
      "TWT_B Training_ (WALK)\n",
      "segments in suitable format\n",
      "labels encoded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyu07\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled model\n",
      "Training Model\n",
      "Epoch 1/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.1571 - val_accuracy: 0.9807 - val_loss: 0.0478\n",
      "Epoch 2/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.9803 - loss: 0.0483 - val_accuracy: 0.9815 - val_loss: 0.0447\n",
      "Epoch 3/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0454 - val_accuracy: 0.9813 - val_loss: 0.0447\n",
      "Epoch 4/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0446 - val_accuracy: 0.9810 - val_loss: 0.0452\n",
      "Epoch 5/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9809 - loss: 0.0449 - val_accuracy: 0.9815 - val_loss: 0.0445\n",
      "Epoch 6/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9813 - loss: 0.0439 - val_accuracy: 0.9817 - val_loss: 0.0424\n",
      "Epoch 7/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9808 - loss: 0.0447 - val_accuracy: 0.9818 - val_loss: 0.0423\n",
      "Epoch 8/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9813 - loss: 0.0436 - val_accuracy: 0.9816 - val_loss: 0.0430\n",
      "Epoch 9/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9798 - loss: 0.0469 - val_accuracy: 0.9807 - val_loss: 0.0469\n",
      "Epoch 10/10\n",
      "\u001b[1m3876/3876\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 436us/step - accuracy: 0.9810 - loss: 0.0441 - val_accuracy: 0.9812 - val_loss: 0.0446\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step - accuracy: 0.9807 - loss: 0.0462\n",
      "\u001b[1m1211/1211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324us/step - accuracy: 0.9807 - loss: 0.0462\n",
      "[0.04480999335646629, 0.9812138676643372]\n"
     ]
    }
   ],
   "source": [
    "activity_segments = segment_activities(160, 36)\n",
    "model = fit_model_TensorFlow(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT Data 5 Second Window, 1 Second Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segments in suitable format\n",
      "Applied FFT\n",
      "encoded labels\n",
      "compiled model\n",
      "Training Model\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fft\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def apply_fft(segment):\n",
    "    # Apply FFT and calculate the magnitude\n",
    "    fft_values = fft(segment)\n",
    "    magnitude = np.abs(fft_values)\n",
    "    return magnitude\n",
    "\n",
    "# Assuming 'activity_segments' is a dictionary with the structure mentioned earlier\n",
    "X_fft = []  # FFT features\n",
    "y = []  # Labels\n",
    "\n",
    "for activity_name, segments in activity_segments.items():\n",
    "    for segment in segments:\n",
    "        # Assuming each segment is a pandas DataFrame with 'x', 'y', 'z' columns\n",
    "        segment_fft = np.vstack([apply_fft(segment[col]) for col in ['x', 'y', 'z']]).T  # Apply FFT to each axis and transpose\n",
    "        X_fft.append(segment_fft)\n",
    "        y.append(activity_name)\n",
    "\n",
    "X_fft = np.array(X_fft, dtype=object)\n",
    "y = np.array(y)\n",
    "print(\"segments in suitable format\\nApplied FFT\")\n",
    "\n",
    "# Encode the activity labels into integers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "print(\"encoded labels\")\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fft, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Adjusting input shapes for LSTM based on FFT features\n",
    "input_shape = (X_train[0].shape[0], X_train[0].shape[1])\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=input_shape, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "print(\"compiled model\\nTraining Model\")\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Since the datasets can have variable lengths due to FFT, use a generator or pad sequences for batching\n",
    "# Example code for model training and evaluation is omitted due to complexity around handling variable input lengths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded the data\n",
      "training and testing data\n",
      "compiled model\n",
      "training model\n",
      "Epoch 1/10\n",
      "13943/13943 [==============================] - 1511s 108ms/step - loss: 1.8652 - accuracy: 0.3859 - val_loss: 1.6013 - val_accuracy: 0.4551\n",
      "Epoch 2/10\n",
      "13943/13943 [==============================] - 1526s 109ms/step - loss: 1.4807 - accuracy: 0.4891 - val_loss: 1.3956 - val_accuracy: 0.5121\n",
      "Epoch 3/10\n",
      "13943/13943 [==============================] - 1439s 103ms/step - loss: 1.2980 - accuracy: 0.5393 - val_loss: 1.2635 - val_accuracy: 0.5506\n",
      "Epoch 4/10\n",
      "13943/13943 [==============================] - 1598s 115ms/step - loss: 1.1838 - accuracy: 0.5724 - val_loss: 1.1821 - val_accuracy: 0.5701\n",
      "Epoch 5/10\n",
      "13943/13943 [==============================] - 1576s 113ms/step - loss: 1.1060 - accuracy: 0.5946 - val_loss: 1.1134 - val_accuracy: 0.5917\n",
      "Epoch 6/10\n",
      "13943/13943 [==============================] - 1494s 107ms/step - loss: 1.0490 - accuracy: 0.6104 - val_loss: 1.0971 - val_accuracy: 0.5957\n",
      "Epoch 7/10\n",
      "13943/13943 [==============================] - 1621s 116ms/step - loss: 1.0082 - accuracy: 0.6226 - val_loss: 1.0362 - val_accuracy: 0.6148\n",
      "Epoch 8/10\n",
      "13943/13943 [==============================] - 1627s 117ms/step - loss: 0.9725 - accuracy: 0.6342 - val_loss: 1.0205 - val_accuracy: 0.6215\n",
      "Epoch 9/10\n",
      "13943/13943 [==============================] - 1605s 115ms/step - loss: 0.9471 - accuracy: 0.6413 - val_loss: 0.9972 - val_accuracy: 0.6268\n",
      "Epoch 10/10\n",
      "13943/13943 [==============================] - 1540s 110ms/step - loss: 0.9211 - accuracy: 0.6496 - val_loss: 0.9840 - val_accuracy: 0.6316\n",
      "4358/4358 [==============================] - 148s 34ms/step - loss: 0.9762 - accuracy: 0.6318\n",
      "Test Loss: 0.976159393787384, Test Accuracy: 0.6317578554153442\n"
     ]
    }
   ],
   "source": [
    "# Pad sequences to ensure uniform input size for LSTM\n",
    "# Find the longest sequence\n",
    "max_length = max(len(sample) for sample in X_fft)\n",
    "\n",
    "# Pad all sequences to the length of the longest sequence\n",
    "X_fft_padded = pad_sequences(X_fft, maxlen=max_length, dtype='float32', padding='post')\n",
    "print(\"padded the data\")\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fft_padded, y_encoded, test_size=0.2, random_state=42)\n",
    "print(\"training and testing data\")\n",
    "# Adjusting input shapes for LSTM based on FFT features\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=input_shape, return_sequences=True),\n",
    "    LSTM(64),\n",
    "    Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"compiled model\")\n",
    "# Train the model\n",
    "print(\"training model\")\n",
    "model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Second Window 3/2 Second Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1_T1_ (WALK)\n",
      "B1_T2_ (WALK)\n",
      "B1_TWT_A_ (WALK)\n",
      "B1_TWT_B_ (WALK)\n",
      "B2_T1_ (WALK)\n",
      "B2_T2_ (WALK)\n",
      "B2_TWT_A_ (WALK)\n",
      "B2_TWT_B_ (WALK)\n",
      "digit symbol task_ (SIT)\n",
      "HR Recovery_ (STAND or SIT)\n",
      "Montreal Cognitive Assessment_ (SIT)\n",
      "Motor Behavioral\n",
      "Motor Behavioral task\n",
      "Motor behavioral task(1)\n",
      "Motor Behavioral Task_ (All conditions seen here)\n",
      "Naughton\n",
      "Naughton Task\n",
      "Naughton test\n",
      "Naughton Test_ (WALK)\n",
      "SOT_ (STAND)\n",
      "TM comfortable speed\n",
      "TM Comfortable speed(1)\n",
      "TM Comfortable Speed_ (WALK)\n",
      "TNT\n",
      "trail making task_ (SIT)\n",
      "Training ITWT - A\n",
      "Training ITWT - B\n",
      "Training ITWT -B\n",
      "Training_ TWT_A\n",
      "Training_ TWT_B\n",
      "Training_TWT_A\n",
      "Training_TWT_B\n",
      "TWT_A training\n",
      "TWT_A Training_ (WALK)\n",
      "TWT_B training\n",
      "TWT_B Training_ (WALK)\n",
      "segments in suitable format\n",
      "labels encoded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyu07\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled model\n",
      "Training Model\n",
      "Epoch 1/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.0887 - val_accuracy: 0.9810 - val_loss: 0.0430\n",
      "Epoch 2/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 436us/step - accuracy: 0.9810 - loss: 0.0428 - val_accuracy: 0.9810 - val_loss: 0.0418\n",
      "Epoch 3/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 433us/step - accuracy: 0.9812 - loss: 0.0419 - val_accuracy: 0.9809 - val_loss: 0.0429\n",
      "Epoch 4/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 424us/step - accuracy: 0.9812 - loss: 0.0421 - val_accuracy: 0.9810 - val_loss: 0.0426\n",
      "Epoch 5/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 427us/step - accuracy: 0.9808 - loss: 0.0429 - val_accuracy: 0.9811 - val_loss: 0.0415\n",
      "Epoch 6/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 438us/step - accuracy: 0.9815 - loss: 0.0412 - val_accuracy: 0.9802 - val_loss: 0.0475\n",
      "Epoch 7/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 432us/step - accuracy: 0.9816 - loss: 0.0413 - val_accuracy: 0.9801 - val_loss: 0.0471\n",
      "Epoch 8/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 426us/step - accuracy: 0.9812 - loss: 0.0421 - val_accuracy: 0.9811 - val_loss: 0.0419\n",
      "Epoch 9/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 418us/step - accuracy: 0.9815 - loss: 0.0414 - val_accuracy: 0.9811 - val_loss: 0.0415\n",
      "Epoch 10/10\n",
      "\u001b[1m11668/11668\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 424us/step - accuracy: 0.9815 - loss: 0.0413 - val_accuracy: 0.9810 - val_loss: 0.0433\n",
      "\u001b[1m3647/3647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - accuracy: 0.9820 - loss: 0.0414\n",
      "\u001b[1m3647/3647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - accuracy: 0.9820 - loss: 0.0414\n",
      "[0.041793517768383026, 0.9817271828651428]\n"
     ]
    }
   ],
   "source": [
    "activity_segments = segment_activities(96, 12)\n",
    "model = fit_model_TensorFlow(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Second Window 1/2 Second Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B1_T1_ (WALK)\n",
      "B1_T2_ (WALK)\n",
      "B1_TWT_A_ (WALK)\n",
      "B1_TWT_B_ (WALK)\n",
      "B2_T1_ (WALK)\n",
      "B2_T2_ (WALK)\n",
      "B2_TWT_A_ (WALK)\n",
      "B2_TWT_B_ (WALK)\n",
      "digit symbol task_ (SIT)\n",
      "HR Recovery_ (STAND or SIT)\n",
      "Montreal Cognitive Assessment_ (SIT)\n",
      "Motor Behavioral\n",
      "Motor Behavioral task\n",
      "Motor behavioral task(1)\n",
      "Motor Behavioral Task_ (All conditions seen here)\n",
      "Naughton\n",
      "Naughton Task\n",
      "Naughton test\n",
      "Naughton Test_ (WALK)\n",
      "SOT_ (STAND)\n",
      "TM comfortable speed\n",
      "TM Comfortable speed(1)\n",
      "TM Comfortable Speed_ (WALK)\n",
      "TNT\n",
      "trail making task_ (SIT)\n",
      "Training ITWT - A\n",
      "Training ITWT - B\n",
      "Training ITWT -B\n",
      "Training_ TWT_A\n",
      "Training_ TWT_B\n",
      "Training_TWT_A\n",
      "Training_TWT_B\n",
      "TWT_A training\n",
      "TWT_A Training_ (WALK)\n",
      "TWT_B training\n",
      "TWT_B Training_ (WALK)\n",
      "segments in suitable format\n",
      "labels encoded\n",
      "compiled model\n",
      "Training Model\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lyu07\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 439us/step - accuracy: 0.9446 - loss: 0.0933 - val_accuracy: 0.9803 - val_loss: 0.0422\n",
      "Epoch 2/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 423us/step - accuracy: 0.9813 - loss: 0.0398 - val_accuracy: 0.9804 - val_loss: 0.0406\n",
      "Epoch 3/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 417us/step - accuracy: 0.9812 - loss: 0.0395 - val_accuracy: 0.9804 - val_loss: 0.0404\n",
      "Epoch 4/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 421us/step - accuracy: 0.9814 - loss: 0.0391 - val_accuracy: 0.9804 - val_loss: 0.0409\n",
      "Epoch 5/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 446us/step - accuracy: 0.9809 - loss: 0.0401 - val_accuracy: 0.9804 - val_loss: 0.0405\n",
      "Epoch 6/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 421us/step - accuracy: 0.9817 - loss: 0.0383 - val_accuracy: 0.9804 - val_loss: 0.0405\n",
      "Epoch 7/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 433us/step - accuracy: 0.9816 - loss: 0.0385 - val_accuracy: 0.9804 - val_loss: 0.0405\n",
      "Epoch 8/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 426us/step - accuracy: 0.9815 - loss: 0.0387 - val_accuracy: 0.9804 - val_loss: 0.0407\n",
      "Epoch 9/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 425us/step - accuracy: 0.9812 - loss: 0.0395 - val_accuracy: 0.9804 - val_loss: 0.0408\n",
      "Epoch 10/10\n",
      "\u001b[1m8795/8795\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 416us/step - accuracy: 0.9810 - loss: 0.0398 - val_accuracy: 0.9804 - val_loss: 0.0408\n",
      "\u001b[1m2749/2749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 319us/step - accuracy: 0.9818 - loss: 0.0379\n",
      "\u001b[1m2749/2749\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - accuracy: 0.9818 - loss: 0.0379\n",
      "[0.03794413059949875, 0.9817491173744202]\n"
     ]
    }
   ],
   "source": [
    "activity_segments = segment_activities()\n",
    "model = fit_model_TensorFlow(activity_segments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
